{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Upload into Environment\n",
    "\n",
    "Here, we stored our files in a Google Cloud Storage so we would not have to read directly from our local machines and change filepaths during development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gbrown\\AppData\\Local\\Temp\\ipykernel_60812\\3497087744.py:14: DtypeWarning: Columns (90) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_url)\n"
     ]
    }
   ],
   "source": [
    "# Public URL after making the file public in the format 'https://storage.googleapis.com/...'\n",
    "file_url = 'https://storage.googleapis.com/home_credit_files/application_train.csv'\n",
    "test_url = 'https://storage.googleapis.com/home_credit_files/application_test.csv'\n",
    "# POS_CASH_balance_url = 'https://storage.googleapis.com/home_credit_files/POS_CASH_balance.csv'\n",
    "# bureau_url = 'https://storage.googleapis.com/home_credit_files/bureau.csv'\n",
    "# bureau_balance_url = 'https://storage.googleapis.com/home_credit_files/bureau.csv'\n",
    "# credit_card_balance = 'https://storage.googleapis.com/home_credit_files/credit_card_balance.csv'\n",
    "# installments_payments = 'https://storage.googleapis.com/home_credit_files/credit_card_balance.csv'\n",
    "# previous_application = 'https://storage.googleapis.com/home_credit_files/previous_application.csv'\n",
    "sample_sub = 'https://storage.googleapis.com/home_credit_files/sample_submission.csv'\n",
    "\n",
    "\n",
    "# Read the CSV directly from the URL\n",
    "df = pd.read_csv(file_url)\n",
    "test_df = pd.read_csv(test_url)\n",
    "\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Below, we perform EDA on the train data set to prepare it for modeling. We began by analyzing the initial data set and obtaining the proportion of the target variable in the train set. About 92% of the data is 0, indicating those that repayed their loans on time. About 8% represent 1, those that did not repay on time.\n",
    "\n",
    "Next, we explored missing variables. We calculated the percentage of missing values per column, and after analyzing the descriptions for each, decided to remove those that were missing greater than 10% of their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    282686\n",
       "1     24825\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    91.927118\n",
       "1     8.072882\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET'].value_counts(normalize = True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data set\n",
    "\n",
    "# calculate total number of missing values for each column\n",
    "missing_values_train = df.isnull().sum()\n",
    "\n",
    "# calculate total number of rows\n",
    "total_rows_train = df.shape[0]\n",
    "\n",
    "# calculate percentage of missing values for each column\n",
    "pct_missing_train = (missing_values_train / total_rows_train) * 100\n",
    "\n",
    "# sort output\n",
    "pct_missing_sorted_train = pct_missing_train.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings = pct_missing_sorted_train.to_frame(name='MissingPercentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with greater than 10% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_missings = missings[(missings['MissingPercentage'] < 10)]\n",
    "filter_missings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing 'FLAG' columns and ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(filter_missings.index)\n",
    "column_list = [item for item in columns if 'FLAG' not in item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing additional unhelpful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = column_list\n",
    "list2 = ['NAME_TYPE_SUITE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE']\n",
    "\n",
    "# Initialize an empty list to store items from list1 that are not in list2\n",
    "items_not_in_list2 = []\n",
    "\n",
    "# Iterate through each item in list1\n",
    "for item in list1:\n",
    "    # Check if the item is not in list2\n",
    "    if item not in list2:\n",
    "        # Add the item to the items_not_in_list2 list\n",
    "        items_not_in_list2.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items_not_in_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "selected_df = df[items_not_in_list2]\n",
    "selected_df\n",
    "\n",
    "test_filtered_columns = [item for item in items_not_in_list2 if item != 'TARGET']\n",
    "test_selected_df = test_df[test_filtered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'TARGET' column\n",
    "target = selected_df['TARGET']\n",
    "\n",
    "# Remove the 'TARGET' column from the dataframe and reassign the result back to selected_df\n",
    "selected_df = selected_df.drop(columns=['TARGET'])\n",
    "\n",
    "# Insert the 'TARGET' column at the beginning of the dataframe\n",
    "selected_df.insert(0, 'TARGET', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix problematic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.loc[:, 'DAYS_EMPLOYED'] = selected_df['DAYS_EMPLOYED'].replace(365243, 0)\n",
    "selected_df = selected_df[selected_df['AMT_INCOME_TOTAL'] <= 9000000]\n",
    "\n",
    "test_selected_df.loc[:, 'DAYS_EMPLOYED'] = test_selected_df['DAYS_EMPLOYED'].replace(365243, 0)\n",
    "test_selected_df = test_selected_df[test_selected_df['AMT_INCOME_TOTAL'] <= 9000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307508, 32)\n",
      "(48744, 31)\n"
     ]
    }
   ],
   "source": [
    "print(selected_df.shape)\n",
    "print(test_selected_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_selected_df should have one less column, TARGET, which is reflected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = selected_df.drop(columns = ['HOUR_APPR_PROCESS_START', 'DAYS_ID_PUBLISH'])\n",
    "test_selected_df = test_selected_df.drop(columns = ['HOUR_APPR_PROCESS_START', 'DAYS_ID_PUBLISH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_selected_df)-set(selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abs value of negatives\n",
    "selected_df['DAYS_LAST_PHONE_CHANGE'] = selected_df.loc[:, 'DAYS_LAST_PHONE_CHANGE'].abs()\n",
    "selected_df['DAYS_REGISTRATION'] = selected_df.loc[:, 'DAYS_REGISTRATION'].abs()\n",
    "selected_df['DAYS_EMPLOYED'] = selected_df.loc[:, 'DAYS_EMPLOYED'].abs()\n",
    "selected_df['DAYS_BIRTH'] = selected_df.loc[:, 'DAYS_BIRTH'].abs()\n",
    "\n",
    "test_selected_df['DAYS_LAST_PHONE_CHANGE'] = test_selected_df.loc[:, 'DAYS_LAST_PHONE_CHANGE'].abs()\n",
    "test_selected_df['DAYS_REGISTRATION'] = test_selected_df.loc[:, 'DAYS_REGISTRATION'].abs()\n",
    "test_selected_df['DAYS_EMPLOYED'] = test_selected_df.loc[:, 'DAYS_EMPLOYED'].abs()\n",
    "test_selected_df['DAYS_BIRTH'] = test_selected_df.loc[:, 'DAYS_BIRTH'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Summary\n",
    "\n",
    "Our initial approach was fairly simplistic for our first attempt. We started by dropped columns that had too much missing data with a cutoff of 10%. We then cut out all 'FLAG' columns as we thought these weren't needed for our basic approach. We fixed a couple columns that had some bad information, and all the while we did the same manipulations to the test set as we did with the train set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789654</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5170.0</td>\n",
       "      <td>2329</td>\n",
       "      <td>19241</td>\n",
       "      <td>0.018850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291656</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9118.0</td>\n",
       "      <td>4469</td>\n",
       "      <td>18064</td>\n",
       "      <td>0.035792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.699787</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2175.0</td>\n",
       "      <td>4458</td>\n",
       "      <td>20038</td>\n",
       "      <td>0.019101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.509677</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1866</td>\n",
       "      <td>13976</td>\n",
       "      <td>0.026392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.425687</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>1</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2191</td>\n",
       "      <td>13040</td>\n",
       "      <td>0.010032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>0.648575</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>17473.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0</td>\n",
       "      <td>412560.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9094.0</td>\n",
       "      <td>5169</td>\n",
       "      <td>19970</td>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>0.684596</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>622413.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>1149</td>\n",
       "      <td>11186</td>\n",
       "      <td>0.035792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>0.632770</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>33205.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>1</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2681.0</td>\n",
       "      <td>3037</td>\n",
       "      <td>15922</td>\n",
       "      <td>0.026392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>0.445701</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>25128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>2731</td>\n",
       "      <td>13968</td>\n",
       "      <td>0.018850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>0.456541</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>24709.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>633</td>\n",
       "      <td>13962</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EXT_SOURCE_2  AMT_GOODS_PRICE  AMT_ANNUITY  CNT_FAM_MEMBERS  \\\n",
       "0          0.789654         450000.0      20560.5              2.0   \n",
       "1          0.291656         180000.0      17370.0              2.0   \n",
       "2          0.699787         630000.0      69777.0              2.0   \n",
       "3          0.509677        1575000.0      49018.5              4.0   \n",
       "4          0.425687         625500.0      32067.0              3.0   \n",
       "...             ...              ...          ...              ...   \n",
       "48739      0.648575         270000.0      17473.5              1.0   \n",
       "48740      0.684596         495000.0      31909.5              4.0   \n",
       "48741      0.632770         315000.0      33205.5              3.0   \n",
       "48742      0.445701         450000.0      25128.0              2.0   \n",
       "48743      0.456541         270000.0      24709.5              2.0   \n",
       "\n",
       "       DAYS_LAST_PHONE_CHANGE  CNT_CHILDREN  AMT_CREDIT  AMT_INCOME_TOTAL  \\\n",
       "0                      1740.0             0    568800.0          135000.0   \n",
       "1                         0.0             0    222768.0           99000.0   \n",
       "2                       856.0             0    663264.0          202500.0   \n",
       "3                      1805.0             2   1575000.0          315000.0   \n",
       "4                       821.0             1    625500.0          180000.0   \n",
       "...                       ...           ...         ...               ...   \n",
       "48739                   684.0             0    412560.0          121500.0   \n",
       "48740                     0.0             2    622413.0          157500.0   \n",
       "48741                   838.0             1    315000.0          202500.0   \n",
       "48742                  2308.0             0    450000.0          225000.0   \n",
       "48743                   327.0             0    312768.0          135000.0   \n",
       "\n",
       "       LIVE_CITY_NOT_WORK_CITY  REG_CITY_NOT_WORK_CITY  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "4                            1                       1   \n",
       "...                        ...                     ...   \n",
       "48739                        0                       0   \n",
       "48740                        1                       1   \n",
       "48741                        0                       0   \n",
       "48742                        1                       1   \n",
       "48743                        0                       0   \n",
       "\n",
       "       REG_CITY_NOT_LIVE_CITY  LIVE_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "...                       ...                          ...   \n",
       "48739                       0                            0   \n",
       "48740                       0                            0   \n",
       "48741                       0                            0   \n",
       "48742                       0                            1   \n",
       "48743                       0                            0   \n",
       "\n",
       "       REG_REGION_NOT_WORK_REGION  REG_REGION_NOT_LIVE_REGION  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "48739                           0                           0   \n",
       "48740                           0                           0   \n",
       "48741                           0                           0   \n",
       "48742                           1                           0   \n",
       "48743                           0                           0   \n",
       "\n",
       "       REGION_RATING_CLIENT_W_CITY  REGION_RATING_CLIENT  DAYS_REGISTRATION  \\\n",
       "0                                2                     2             5170.0   \n",
       "1                                2                     2             9118.0   \n",
       "2                                2                     2             2175.0   \n",
       "3                                2                     2             2000.0   \n",
       "4                                2                     2             4000.0   \n",
       "...                            ...                   ...                ...   \n",
       "48739                            3                     3             9094.0   \n",
       "48740                            2                     2             3015.0   \n",
       "48741                            2                     2             2681.0   \n",
       "48742                            2                     2             1461.0   \n",
       "48743                            2                     2             1072.0   \n",
       "\n",
       "       DAYS_EMPLOYED  DAYS_BIRTH  REGION_POPULATION_RELATIVE  \n",
       "0               2329       19241                    0.018850  \n",
       "1               4469       18064                    0.035792  \n",
       "2               4458       20038                    0.019101  \n",
       "3               1866       13976                    0.026392  \n",
       "4               2191       13040                    0.010032  \n",
       "...              ...         ...                         ...  \n",
       "48739           5169       19970                    0.002042  \n",
       "48740           1149       11186                    0.035792  \n",
       "48741           3037       15922                    0.026392  \n",
       "48742           2731       13968                    0.018850  \n",
       "48743            633       13962                    0.006629  \n",
       "\n",
       "[48744 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab numeric columns\n",
    "numeric_cols = selected_df.drop(['SK_ID_CURR'], axis=1).select_dtypes(include='number')\n",
    "numeric_cols\n",
    "\n",
    "test_numeric_cols = test_selected_df.drop(['SK_ID_CURR'], axis=1).select_dtypes(include='number')\n",
    "test_numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EXT_SOURCE_2', 'AMT_GOODS_PRICE', 'AMT_ANNUITY', 'CNT_FAM_MEMBERS', 'DAYS_LAST_PHONE_CHANGE', 'CNT_CHILDREN', 'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'LIVE_CITY_NOT_WORK_CITY', 'REG_CITY_NOT_WORK_CITY', 'REG_CITY_NOT_LIVE_CITY', 'LIVE_REGION_NOT_WORK_REGION', 'REG_REGION_NOT_WORK_REGION', 'REG_REGION_NOT_LIVE_REGION', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'DAYS_REGISTRATION', 'DAYS_EMPLOYED', 'DAYS_BIRTH', 'REGION_POPULATION_RELATIVE']\n",
      "['EXT_SOURCE_2', 'AMT_GOODS_PRICE', 'AMT_ANNUITY', 'CNT_FAM_MEMBERS', 'DAYS_LAST_PHONE_CHANGE', 'CNT_CHILDREN', 'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'LIVE_CITY_NOT_WORK_CITY', 'REG_CITY_NOT_WORK_CITY', 'REG_CITY_NOT_LIVE_CITY', 'LIVE_REGION_NOT_WORK_REGION', 'REG_REGION_NOT_WORK_REGION', 'REG_REGION_NOT_LIVE_REGION', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'DAYS_REGISTRATION', 'DAYS_EMPLOYED', 'DAYS_BIRTH', 'REGION_POPULATION_RELATIVE']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of numeric column names excluding target for imputations\n",
    "\n",
    "column_names = numeric_cols.columns.tolist()\n",
    "my_list = [x for x in column_names if x != 'TARGET']\n",
    "print(my_list)\n",
    "\n",
    "test_column_names = numeric_cols.columns.tolist()\n",
    "test_my_list = [x for x in column_names if x != 'TARGET']\n",
    "print(test_my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N/a Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleImputer instance\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit and transform the selected numeric columns\n",
    "selected_df.loc[:, my_list] = imputer.fit_transform(selected_df.loc[:, my_list])\n",
    "\n",
    "test_selected_df.loc[:, test_my_list] = imputer.fit_transform(test_selected_df.loc[:, test_my_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df['CREDIT_TO_INCOME'] = selected_df['AMT_CREDIT']/selected_df['AMT_INCOME_TOTAL']\n",
    "\n",
    "test_selected_df['CREDIT_TO_INCOME'] = test_selected_df['AMT_CREDIT']/test_selected_df['AMT_INCOME_TOTAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler to scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalar_list = ['EXT_SOURCE_2','AMT_GOODS_PRICE','AMT_ANNUITY','AMT_CREDIT','AMT_INCOME_TOTAL','REGION_RATING_CLIENT_W_CITY','REGION_RATING_CLIENT','CREDIT_TO_INCOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307508, 31)\n",
      "(48744, 30)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "selected_df[my_list] = scaler.fit_transform(selected_df[my_list])\n",
    "\n",
    "test_selected_df[test_my_list] = scaler.fit_transform(test_selected_df[test_my_list])\n",
    "\n",
    "print(selected_df.shape)\n",
    "print(test_selected_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307508, 110)\n",
      "(48744, 106)\n",
      "set()\n",
      "{'NAME_INCOME_TYPE_Maternity leave', 'NAME_FAMILY_STATUS_Unknown', 'CODE_GENDER_XNA', 'TARGET'}\n",
      "(307508, 107)\n",
      "(48744, 106)\n"
     ]
    }
   ],
   "source": [
    "# dummy encoding data set\n",
    "\n",
    "selected_df = pd.get_dummies(selected_df, drop_first=True)\n",
    "\n",
    "test_selected_df = pd.get_dummies(test_selected_df, drop_first=True)\n",
    "\n",
    "print(selected_df.shape)\n",
    "print(test_selected_df.shape)\n",
    "\n",
    "print(set(test_selected_df)-set(selected_df))\n",
    "print(set(selected_df)-set(test_selected_df))\n",
    "\n",
    "columns_to_drop = set(selected_df.columns) - set(test_selected_df.columns)\n",
    "columns_to_drop.discard('TARGET')\n",
    "selected_df = selected_df.drop(columns=list(columns_to_drop), axis=1)\n",
    "\n",
    "print(selected_df.shape)\n",
    "print(test_selected_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Target and Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selected_df.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "y = selected_df['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling\n",
    "\n",
    "We created an upsampled fold of data to test how this effected each of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selected_df.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "y = selected_df['TARGET']\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority = data[data.TARGET==0]\n",
    "minority = data[data.TARGET==1]\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority, \n",
    "                              replace=True,     # sample with replacement\n",
    "                              n_samples=len(majority),    # to match majority class size\n",
    "                              random_state=42)  # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "upsampled_data = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "# Checking the new class distribution\n",
    "upsampled_data.TARGET.value_counts()\n",
    "\n",
    "X_upsampled = upsampled_data.drop('TARGET', axis=1)\n",
    "y_upsampled = upsampled_data['TARGET']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9206524708300272\n",
      "Train Accuracy using built-in score: 0.9206524708300272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, \n",
    "                        eval_metric='logloss', \n",
    "                        n_estimators=100, \n",
    "                        max_depth=6\n",
    "                        )\n",
    "\n",
    "xgb_clf.fit(X, y)\n",
    "\n",
    "xgb_y_pred = xgb_clf.predict(X)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y, xgb_y_pred)\n",
    "\n",
    "print(\"Train Accuracy:\", xgb_accuracy)\n",
    "print(\"Train Accuracy using built-in score:\", xgb_clf.score(X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
